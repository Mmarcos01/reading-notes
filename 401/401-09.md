[Home](../README.md) 

[Dunder Methods](https://dbader.org/blog/python-dunder-methods) 


Dunder methods are predefined methods in python that start and end with double underscores, such as \__init__ or \__str__ Dunder methods let you emulate the behavior of built-in types.  

The Python data model and lets developers tap into features like sequences, iteration, operator overloading, attribute access, etc. Python’s data model can be viewed as as a powerful API you can interface with by implementing one or more dunder methods. 

**\__init__**
To construct account objects from the Account class, use a constructor which in Python is the \__init__ dunder.

**\__str__, \__repr__**
To provide a string representation of your object for the consumer of your class, two ways:  

\__repr__: The “official” string representation of an object. This is how you would make an object of the class. The goal of \__repr__ is to be unambiguous.

\__str__: The “informal” or nicely printable string representation of an object. This is for the enduser.

### More dunder methods

**Iteration: \__len__, \__getitem__, \__reversed__**

**Operator Overloading for Comparing Accounts: \__eq__, \__lt__**

**Operator Overloading for Merging Accounts: \__add__**

**Callable Python Objects: \__call__**

**Context Manager Support and the With Statement: \__enter__, \__exit__**


## Statistics and Probability

[Statistics - Probability](dataquest.io/blog/basic-statistics-in-python-probability/)

### What is probability?

Probability is the chance of an event happening. Sample space is the set of all possible events that can happen. To calculate the probability of an event occurring, count how many times the event of interest can occur and divide it by the sample space. Probability gives us the framework for making predictions.

In normal distribution the high point represents the event with the highest probability of occurring (or the mean). On either side as you get further away from the event, the probability drops (frequency), forming a bell-shape.

**Central Limit Theorem** lets us know that the average of many trials means will approach the true mean

**Three Sigma Rule** tells us how much the data will be spread out around this mean.

**The Z-score** is a simple calculation that answers the question, “Given a data point, how many standard deviations is it away from the mean?